#!/usr/bin/env python3
"""å½¢æ…‹ç´ è§£æçµæœè¡¨ç¤ºãƒ„ãƒ¼ãƒ«ã€‚."""

from __future__ import annotations

import argparse
import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
src_path = project_root / "src"
sys.path.insert(0, str(src_path))

try:
    from detector.core.mora import count_mora, normalize_reading
    from detector.tokenizer.sudachi import SudachiTokenizer
except ImportError as e:
    print(f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    print("src/detector/ä»¥ä¸‹ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
    sys.exit(1)


def analyze_text(text: str, verbose: bool = False) -> None:
    """ãƒ†ã‚­ã‚¹ãƒˆã®å½¢æ…‹ç´ è§£æçµæœã‚’è¡¨ç¤ºã™ã‚‹ã€‚."""
    print(f"ğŸ“ å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ: {text}")
    print("=" * 80)

    # æ—¢å­˜ã®SudachiTokenizerã‚’ä½¿ç”¨ã—ã¦ã€è©³ç´°æƒ…å ±ã‚‚å–å¾—
    tokenizer = SudachiTokenizer(mode="C")

    try:
        # è©³ç´°ãªå½¢æ…‹ç´ è§£æã®ãŸã‚ã«SudachiPyã‚’ç›´æ¥ä½¿ç”¨
        sudachi_tokenizer = tokenizer.tokenizer
        morphemes = sudachi_tokenizer.tokenize(text, tokenizer._mode)

        if not morphemes:
            print("âŒ å½¢æ…‹ç´ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return

        print(f"ğŸ” å½¢æ…‹ç´ è§£æçµæœ ({len(morphemes)}å½¢æ…‹ç´ )")
        print("-" * 80)

        total_mora = 0

        for i, morpheme in enumerate(morphemes, 1):
            # åŸºæœ¬æƒ…å ±
            surface = morpheme.surface()
            reading_form = morpheme.reading_form()
            normalized_form = morpheme.normalized_form()
            dictionary_form = morpheme.dictionary_form()

            # è©³ç´°ãªå“è©æƒ…å ±ã‚’å–å¾—
            pos_tags = morpheme.part_of_speech()

            # èª­ã¿ã‚’æ­£è¦åŒ–ã—ã¦ãƒ¢ãƒ¼ãƒ©æ•°è¨ˆç®—
            normalized_reading = normalize_reading(reading_form)
            mora_count = count_mora(normalized_reading)
            total_mora += mora_count

            print(f"{i:2d}. è¡¨è¨˜: {surface:<12} èª­ã¿: {reading_form:<15}")
            print(f"    æ­£è¦åŒ–å½¢: {normalized_form:<10} è¾æ›¸å½¢: {dictionary_form:<15}")

            # å“è©ã®è©³ç´°æƒ…å ±
            pos_labels = ["å¤§åˆ†é¡", "ä¸­åˆ†é¡", "å°åˆ†é¡", "ç´°åˆ†é¡", "æ´»ç”¨å‹", "æ´»ç”¨å½¢"]
            print("    å“è©æƒ…å ±:")
            for _j, (label, pos_tag) in enumerate(zip(pos_labels, pos_tags[:6], strict=False)):
                if pos_tag and pos_tag != "*":
                    print(f"      {label}: {pos_tag}")

            print(f"    ãƒ¢ãƒ¼ãƒ©æ•°: {mora_count}")

            if verbose:
                # ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ã‚’è¡¨ç¤º
                if len(pos_tags) > 6:
                    extra_tags = [tag for tag in pos_tags[6:] if tag != "*"]
                    if extra_tags:
                        print(f"    è¿½åŠ å“è©æƒ…å ±: {', '.join(extra_tags)}")

                # å…¨å“è©æƒ…å ±ã®ãƒªã‚¹ãƒˆè¡¨ç¤º
                print(f"    å…¨å“è©ã‚¿ã‚°: {pos_tags}")

                # èªå½™ç´ æƒ…å ±ï¼ˆåˆ©ç”¨å¯èƒ½ãªãƒ¡ã‚½ãƒƒãƒ‰ã®ã¿ï¼‰
                try:
                    word_id = morpheme.word_id()
                    print(f"    èªå½™ç´ ID: {word_id}")
                except AttributeError:
                    print("    èªå½™ç´ ID: (å–å¾—ä¸å¯)")

                # ãã®ä»–ã®åˆ©ç”¨å¯èƒ½ãªæƒ…å ±
                try:
                    begin = morpheme.begin()
                    end = morpheme.end()
                    print(f"    ä½ç½®: {begin}-{end}")
                except AttributeError:
                    pass

            print()

        print(f"ğŸ“Š ç·ãƒ¢ãƒ¼ãƒ©æ•°: {total_mora}")

        # å·æŸ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ã®æ¯”è¼ƒ
        patterns = [
            ("æ¨™æº–å·æŸ³", [5, 7, 5]),
            ("å­—ä½™ã‚Š5-8-5", [5, 8, 5]),
            ("å­—ä½™ã‚Š6-7-5", [6, 7, 5]),
            ("å­—ä½™ã‚Š5-7-6", [5, 7, 6]),
        ]

        print("\nğŸ‹ å·æŸ³ãƒ‘ã‚¿ãƒ¼ãƒ³é©åˆæ€§:")
        print("-" * 40)
        for name, pattern in patterns:
            expected = sum(pattern)
            match = "âœ…" if total_mora == expected else "âŒ"
            print(f"{match} {name}: {pattern} (åˆè¨ˆ{expected}ãƒ¢ãƒ¼ãƒ©)")

    except Exception as e:
        print(f"âŒ è§£æã‚¨ãƒ©ãƒ¼: {e}")
        import traceback

        if verbose:
            traceback.print_exc()
        sys.exit(1)


def main() -> None:
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°ã€‚."""
    parser = argparse.ArgumentParser(
        description="æ–‡å­—åˆ—ã®å½¢æ…‹ç´ è§£æçµæœã¨å“è©æƒ…å ±ã‚’è¡¨ç¤ºã—ã¾ã™",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  python analyze.py "å¤æ± ã‚„è›™é£›ã³è¾¼ã‚€æ°´ã®éŸ³"
  python analyze.py "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¯æ¥½ã—ã„ä½œæ¥­ã "
        """,
    )

    parser.add_argument("text", help="è§£æã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ")

    parser.add_argument("-v", "--verbose", action="store_true", help="è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º")

    args = parser.parse_args()

    if not args.text.strip():
        print("âŒ ç©ºã®ãƒ†ã‚­ã‚¹ãƒˆã¯è§£æã§ãã¾ã›ã‚“")
        sys.exit(1)

    analyze_text(args.text, verbose=args.verbose)


if __name__ == "__main__":
    main()
